{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:12:12.955164Z",
     "start_time": "2025-05-17T11:12:12.845367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mpqqq"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:12:13.278453Z",
     "start_time": "2025-05-17T11:12:12.994138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    smooth_landmarks=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ],
   "id": "2e90f7c9e4e4e903",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747480333.212330  191209 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1747480333.252079  211159 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.0.4-1~bpo12+1), renderer: Mesa Intel(R) Graphics (ADL GT2)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:15:13.463672Z",
     "start_time": "2025-05-17T11:12:13.304706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initializing current time and precious time for calculating the FPS\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "while capture.isOpened():\n",
    "    # capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # resizing the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    # Converting back the RGB image to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Drawing the Facial Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.face_landmarks,\n",
    "      mp_holistic.FACEMESH_CONTOURS,\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(255,0,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      ),\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(0,255,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      )\n",
    "    )\n",
    "\n",
    "    # Drawing Right hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.right_hand_landmarks,\n",
    "      mp_holistic.HAND_CONNECTIONS\n",
    "    )\n",
    "\n",
    "    # Drawing Left hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.left_hand_landmarks,\n",
    "      mp_holistic.HAND_CONNECTIONS\n",
    "    )\n",
    "\n",
    "    # Calculating the FPS\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime-previousTime)\n",
    "    previousTime = currentTime\n",
    "\n",
    "    # Displaying FPS on the image\n",
    "    cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "\n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "4f9d01819cf0b55b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1747480333.370968  211151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.474754  211155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.479649  211152 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.481142  211153 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.484879  211155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.516589  211146 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.547169  211147 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747480333.550512  211154 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:15:14.073930Z",
     "start_time": "2025-05-17T11:15:14.034774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code to access landmarks\n",
    "for landmark in mp_holistic.HandLandmark:\n",
    "    print(landmark, landmark.value)\n",
    "\n",
    "print(mp_holistic.HandLandmark.WRIST.value)"
   ],
   "id": "4b8996642a83a9f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T11:15:14.162438Z",
     "start_time": "2025-05-17T11:15:14.156856Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f0b671a0bfe96e6c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
